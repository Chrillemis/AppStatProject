{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ISLP.models import ModelSpec as MS\n",
    "import statsmodels.api as sm\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PathToRepo = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "Df = pd.read_csv(PathToRepo + '\\\\Data\\\\Faellesdata_cleaned.csv')\n",
    "\n",
    "x = Df.drop('IsMigratorInt', axis=1) \n",
    "for i in range(0, x.shape[1]): #Standardizing the data\n",
    "    x.iloc[:,i] = (x.iloc[:, i] - x.iloc[:, i].mean())/x.iloc[:, i].std()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, Df['IsMigratorInt'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = MS(x_train, intercept = False).fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7999, 15)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelnn = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[x_train.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.7989 - loss: 0.4474\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.8502 - loss: 0.3237\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.8536 - loss: 0.3009\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8589 - loss: 0.2858\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8608 - loss: 0.2874\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.2753\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.8685 - loss: 0.2729\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8670 - loss: 0.2739\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.8799 - loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.8740 - loss: 0.2588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23cc83827d0>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelnn.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8768 - loss: 0.2614  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2641180455684662, 0.8694999814033508]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.evaluate(MS(x_test, intercept = False).fit_transform(x_test), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "0.8695\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adam'"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.optimizer.get_config()['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_allow_non_tensor_positional_args',\n",
       " '_api_export_path',\n",
       " '_api_export_symbol_id',\n",
       " '_assert_input_compatibility',\n",
       " '_auto_config',\n",
       " '_build_by_run_for_kwargs',\n",
       " '_build_by_run_for_single_pos_arg',\n",
       " '_build_shapes_dict',\n",
       " '_call_has_mask_arg',\n",
       " '_call_has_training_arg',\n",
       " '_call_signature',\n",
       " '_called',\n",
       " '_check_load_own_variables',\n",
       " '_check_quantize_args',\n",
       " '_check_super_called',\n",
       " '_checkpoint_adapter',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_convert_input_args',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_dtype_policy',\n",
       " '_export_to_saved_model_graph',\n",
       " '_flatten_layers',\n",
       " '_float8_build',\n",
       " '_float8_call',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_context',\n",
       " '_get_kernel_with_merged_lora',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_own_losses',\n",
       " '_get_regularization_losses',\n",
       " '_handle_deferred_dependencies',\n",
       " '_inbound_nodes',\n",
       " '_initialize_tracker',\n",
       " '_input_shape_arg',\n",
       " '_input_spec',\n",
       " '_int8_build',\n",
       " '_int8_call',\n",
       " '_kernel',\n",
       " '_layers',\n",
       " '_lock',\n",
       " '_lock_state',\n",
       " '_lookup_dependency',\n",
       " '_loss_ids',\n",
       " '_losses',\n",
       " '_losses_override',\n",
       " '_maybe_build',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_reset_call_context',\n",
       " '_metrics',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_non_trainable_variables',\n",
       " '_not_implemented_error',\n",
       " '_obj_type',\n",
       " '_object_identifier',\n",
       " '_open_name_scope',\n",
       " '_outbound_nodes',\n",
       " '_parent_path',\n",
       " '_path',\n",
       " '_post_build',\n",
       " '_post_track_variable',\n",
       " '_post_untrack_variable',\n",
       " '_preload_simple_restoration',\n",
       " '_quantization_mode_error',\n",
       " '_restore_from_tensors',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_seed_generators',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_setattr_hook',\n",
       " '_setattr_tracking',\n",
       " '_supports_masking',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_trackable_children',\n",
       " '_tracked',\n",
       " '_tracker',\n",
       " '_trainable',\n",
       " '_trainable_variables',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unpickle_model',\n",
       " '_untrack_variable',\n",
       " '_update_uid',\n",
       " 'activation',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'autocast',\n",
       " 'bias',\n",
       " 'bias_constraint',\n",
       " 'bias_initializer',\n",
       " 'bias_regularizer',\n",
       " 'build',\n",
       " 'build_from_config',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_spec',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'enable_lora',\n",
       " 'from_config',\n",
       " 'get_build_config',\n",
       " 'get_config',\n",
       " 'get_weights',\n",
       " 'input',\n",
       " 'input_dtype',\n",
       " 'input_spec',\n",
       " 'kernel',\n",
       " 'kernel_constraint',\n",
       " 'kernel_initializer',\n",
       " 'kernel_regularizer',\n",
       " 'load_own_variables',\n",
       " 'lora_enabled',\n",
       " 'lora_rank',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_variables',\n",
       " 'name',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'output',\n",
       " 'path',\n",
       " 'quantization_mode',\n",
       " 'quantize',\n",
       " 'quantized_build',\n",
       " 'quantized_call',\n",
       " 'save_own_variables',\n",
       " 'set_weights',\n",
       " 'stateless_call',\n",
       " 'supports_jit',\n",
       " 'supports_masking',\n",
       " 'symbolic_call',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'units',\n",
       " 'use_bias',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(modelnn.get_layer(index=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.get_layer(index=0).units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary_crossentropy'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame({'a':[1,2,3],'b':[4,5,6]})\n",
    "\n",
    "# columns=[('c','a'),('c','b')]\n",
    "\n",
    "# df.columns=pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "# df=pd.DataFrame({'a':[1,2,3],'b':[4,5,6]})\n",
    "\n",
    "# columns=[('d','a'),('d','b')]\n",
    "# df.columns=pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Models = []\n",
    "modelconfig = modelnn.get_config()\n",
    "for i in range(1, len(modelconfig['layers'])):\n",
    "    neurons = modelconfig['layers'][i]['config']['units']\n",
    "    activation = modelconfig['layers'][i]['config']['activation']\n",
    "    layer_type = modelconfig['layers'][i]['class_name']\n",
    "    Models.append({'Model': 'Neural Network 1', \n",
    "                   'Optimizer': modelnn.optimizer.get_config()['name'], \n",
    "                   'Loss': modelnn.loss, \n",
    "                   'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), \n",
    "                   'Layers': i, \n",
    "                   'Neurons': neurons, \n",
    "                   'Activation': activation})\n",
    "\n",
    "ModelsDf = pd.DataFrame(Models)\n",
    "# ModelsDf = ModelsDf.set_index('Model', append=True).swaplevel(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelsoftmax = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[x_train.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.8108 - loss: 0.4377\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.8511 - loss: 0.3239\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.8543 - loss: 0.2985\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.8616 - loss: 0.2870\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8693 - loss: 0.2764\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.8672 - loss: 0.2715\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.8725 - loss: 0.2584\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8694 - loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.8705 - loss: 0.2679\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.8836 - loss: 0.2494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23cc8633010>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsoftmax.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelsoftmax.fit(x_train, keras.utils.to_categorical(y_train), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step\n"
     ]
    }
   ],
   "source": [
    "Models = []\n",
    "modelconfig = modelnn.get_config()\n",
    "modelnn = modelsoftmax\n",
    "for i in range(1, len(modelconfig['layers'])):\n",
    "    neurons = modelconfig['layers'][i]['config']['units']\n",
    "    activation = modelconfig['layers'][i]['config']['activation']\n",
    "    layer_type = modelconfig['layers'][i]['class_name']\n",
    "    Models.append({'Model': 'Neural Network 2'\n",
    "                   , 'Optimizer': modelnn.optimizer.get_config()['name']\n",
    "                   , 'Loss': modelnn.loss\n",
    "                    , 'Accuracy': accuracy_score(y_test, np.argmax(modelsoftmax.predict(MS(x_test, intercept = False).fit_transform(x_test)), axis=1))\n",
    "                   , 'Layers': i, 'Neurons': neurons\n",
    "                   , 'Activation': activation})\n",
    "    # Models.append({'Model': 'Neural Network 2', 'Optimizer': modelnn.optimizer.get_config()['name'], 'Loss': modelnn.loss, 'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), 'Layers': i, 'Neurons': neurons, 'Activation': activation})\n",
    "NewModelDf = pd.DataFrame(Models)\n",
    "ModelsDf = ModelsDf.merge(NewModelDf, how='outer', on=['Model', 'Layers', 'Neurons', 'Activation', 'Optimizer', 'Loss', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.2836  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28365808725357056, 0.8550000190734863]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsoftmax.evaluate(MS(x_test, intercept = False).fit_transform(x_test), keras.utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, np.argmax(modelsoftmax.predict(MS(x_test, intercept = False).fit_transform(x_test)), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.8568 - loss: 0.2727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2757652997970581, 0.8565000295639038]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=[x_train.shape[1]]),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "modelnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelnn.fit(x_train, y_train, epochs=100, verbose = 0)\n",
    "modelnn.evaluate(MS(x_test, intercept = False).fit_transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step\n"
     ]
    }
   ],
   "source": [
    "Models = []\n",
    "modelconfig = modelnn.get_config()\n",
    "for i in range(1, len(modelconfig['layers'])):\n",
    "    neurons = modelconfig['layers'][i]['config']['units']\n",
    "    activation = modelconfig['layers'][i]['config']['activation']\n",
    "    layer_type = modelconfig['layers'][i]['class_name']\n",
    "    Models.append({'Model': 'Neural Network 3', \n",
    "                   'Optimizer': modelnn.optimizer.get_config()['name'], \n",
    "                   'Loss': modelnn.loss, \n",
    "                   'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), \n",
    "                   'Layers': i, \n",
    "                   'Neurons': neurons, \n",
    "                   'Activation': activation})\n",
    "NewModelDf = pd.DataFrame(Models)\n",
    "ModelsDf = ModelsDf.merge(NewModelDf, how='outer', on=['Model', 'Layers', 'Neurons', 'Activation', 'Optimizer', 'Loss', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelnn = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=[x_train.shape[1]]),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.2908 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2864534258842468, 0.8510000109672546]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelnn.fit(x_train, y_train, epochs=100, verbose = 0)\n",
    "modelnn.evaluate(MS(x_test, intercept = False).fit_transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step\n"
     ]
    }
   ],
   "source": [
    "Models = []\n",
    "modelconfig = modelnn.get_config()\n",
    "modelconfig['layers'][2]\n",
    "# ModelsDf\n",
    "for i in range(1, len(modelconfig['layers'])):\n",
    "    layer_type = modelconfig['layers'][i]['class_name']\n",
    "    if layer_type == 'Dropout':\n",
    "        rate = modelconfig['layers'][i]['config']['rate']\n",
    "        Models.append({'Model': 'Neural Network 4', \n",
    "                       'Optimizer': modelnn.optimizer.get_config()['name'], \n",
    "                       'Loss': modelnn.loss, \n",
    "                       'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), \n",
    "                       'Layers': i, \n",
    "                       'Rate': rate})\n",
    "        continue\n",
    "    neurons = modelconfig['layers'][i]['config']['units']\n",
    "    activation = modelconfig['layers'][i]['config']['activation']\n",
    "    Models.append({'Model': 'Neural Network 4', \n",
    "                   'Optimizer': modelnn.optimizer.get_config()['name'], \n",
    "                   'Loss': modelnn.loss, \n",
    "                   'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), \n",
    "                   'Layers': i, \n",
    "                   'Neurons': neurons, \n",
    "                   'Activation': activation})\n",
    "NewModelDf = pd.DataFrame(Models)\n",
    "ModelsDf = ModelsDf.merge(NewModelDf, how='outer', on=['Model', 'Layers', 'Neurons', 'Activation', 'Optimizer', 'Loss', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn = keras.models.load_model('modelnn.keras')\n",
    "accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note That the full data file is not included in the repository, as it is too large and that the code below takes over 30 mins to run. The code above just loads the model and calculates the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astropy.io import ascii\n",
    "# FullData = ascii.read(PathToRepo + '\\\\Data\\\\m12i_res7100_mhdcv.disk.ecsv', guess = False)\n",
    "# FullData = FullData.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FullData['IsMigrator'] = abs(FullData['Rcyl'] - FullData['Rcyl_form']) > 1.5\n",
    "# FullData['IsMigratorInt'] = FullData['IsMigrator'].astype(int)\n",
    "# FullData = FullData.drop(['rsph', 'x', 'y',  'vx', 'vy', \n",
    "#        'rsph_form', 'x_form', 'y_form', 'z_form', 'vx_form', 'vy_form',\n",
    "#        'vz_form', 'Rcyl_form', 'phi_form', 'vRcyl_form', 'vphi_form', \"IsMigrator\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df = FullData\n",
    "# x = Df.drop('IsMigratorInt', axis=1) \n",
    "# for i in range(0, x.shape[1]): #Standardizing the data\n",
    "#     x.iloc[:,i] = (x.iloc[:, i] - x.iloc[:, i].mean())/x.iloc[:, i].std()\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, Df['IsMigratorInt'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelnn = keras.Sequential([\n",
    "#     layers.Dense(16, activation='relu', input_shape=[x_train.shape[1]]),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# modelnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# modelnn.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Models = []\n",
    "\n",
    "modelconfig = modelnn.get_config()\n",
    "modelnn = keras.models.load_model('modelnn.keras')\n",
    "for i in range(1, len(modelconfig['layers'])):\n",
    "    neurons = modelconfig['layers'][i]['config']['units']\n",
    "    activation = modelconfig['layers'][i]['config']['activation']\n",
    "    layer_type = modelconfig['layers'][i]['class_name']\n",
    "    Models.append({'Model': 'Neural Network 5', \n",
    "                   'Optimizer': modelnn.optimizer.get_config()['name'], \n",
    "                   'Loss': modelnn.loss, \n",
    "                   'Accuracy': accuracy_score(y_test, modelnn.predict(MS(x_test, intercept = False).fit_transform(x_test)) > 0.5), \n",
    "                   'Layers': i, \n",
    "                   'Neurons': neurons, \n",
    "                   'Activation': activation})\n",
    "NewModelDf = pd.DataFrame(Models)\n",
    "ModelsDf = ModelsDf.merge(NewModelDf, how='outer', on=['Model', 'Layers', 'Neurons', 'Activation', 'Optimizer', 'Loss', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = ModelsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsDf = asd\n",
    "\n",
    "ModelsDf\n",
    "ModelsDf.index = ModelsDf['Model']\n",
    "ModelsDf = ModelsDf.drop('Model', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsDf.index = ModelsDf.index.rename('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsDf.index = pd.MultiIndex.from_tuples([(ModelsDf.index[i],i) for i in range(0, ModelsDf.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Temp\\ipykernel_51116\\2923490059.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ModelsDf['Loss'].replace(\"_\", \"\\textunderscore \", regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "ModelsDf['Loss'].replace(\"_\", \"\\textunderscore \", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Neural Network 1</th>\n",
       "      <th>0</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Neural Network 2</th>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>categorical\\textunderscore crossentropy</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>categorical\\textunderscore crossentropy</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adam</td>\n",
       "      <td>categorical\\textunderscore crossentropy</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Neural Network 3</th>\n",
       "      <th>6</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Neural Network 4</th>\n",
       "      <th>8</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>adam</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Neural Network 5</th>\n",
       "      <th>13</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>binary\\textunderscore crossentropy</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Optimizer                                     Loss  \\\n",
       "Neural Network 1 0       adam       binary\\textunderscore crossentropy   \n",
       "                 1       adam       binary\\textunderscore crossentropy   \n",
       "                 2       adam       binary\\textunderscore crossentropy   \n",
       "Neural Network 2 3       adam  categorical\\textunderscore crossentropy   \n",
       "                 4       adam  categorical\\textunderscore crossentropy   \n",
       "                 5       adam  categorical\\textunderscore crossentropy   \n",
       "Neural Network 3 6       adam       binary\\textunderscore crossentropy   \n",
       "                 7       adam       binary\\textunderscore crossentropy   \n",
       "Neural Network 4 8       adam       binary\\textunderscore crossentropy   \n",
       "                 9       adam       binary\\textunderscore crossentropy   \n",
       "                 10      adam       binary\\textunderscore crossentropy   \n",
       "                 11      adam       binary\\textunderscore crossentropy   \n",
       "                 12      adam       binary\\textunderscore crossentropy   \n",
       "Neural Network 5 13   rmsprop       binary\\textunderscore crossentropy   \n",
       "                 14   rmsprop       binary\\textunderscore crossentropy   \n",
       "\n",
       "                     Accuracy  Layers  Neurons Activation  Rate  \n",
       "Neural Network 1 0     0.8695       1     64.0       relu   NaN  \n",
       "                 1     0.8695       2     64.0       relu   NaN  \n",
       "                 2     0.8695       3      1.0    sigmoid   NaN  \n",
       "Neural Network 2 3     0.8550       1     64.0       relu   NaN  \n",
       "                 4     0.8550       2     64.0       relu   NaN  \n",
       "                 5     0.8550       3      1.0    sigmoid   NaN  \n",
       "Neural Network 3 6     0.8565       1     16.0       relu   NaN  \n",
       "                 7     0.8565       2      1.0    sigmoid   NaN  \n",
       "Neural Network 4 8     0.8510       1     16.0       relu   NaN  \n",
       "                 9     0.8510       2      NaN        NaN   0.5  \n",
       "                 10    0.8510       3     16.0       relu   NaN  \n",
       "                 11    0.8510       4      NaN        NaN   0.5  \n",
       "                 12    0.8510       5      1.0    sigmoid   NaN  \n",
       "Neural Network 5 13    0.8800       1     16.0       relu   NaN  \n",
       "                 14    0.8800       2      1.0    sigmoid   NaN  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelsDf.to_latex(PathToRepo + '\\\\Tables\\\\Models.tex', index_names = True, na_rep='-', multirow = True, float_format=\"%.2f\", caption=\"Differnet neural networks\", label=\"tab:RawData\", position=\"h!\")\n",
    "ModelsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelnn.save('modelnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
